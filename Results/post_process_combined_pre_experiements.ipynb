{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_paths = [os.path.realpath(\"./Pre-experiment1\"), os.path.realpath(\"./Pre-experiment2\")]\n",
    "\n",
    "# load multirun yaml Omgeaconf\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "multirun_yaml_paths = []\n",
    "multi_cfgs = []\n",
    "sweep_cfgs = []\n",
    "for experiment_path in experiment_paths:\n",
    "    multirun_yaml_path = glob(f\"{experiment_path}/**/multirun.yaml\", recursive=True)[0]\n",
    "\n",
    "    multi_cfg = OmegaConf.load(multirun_yaml_path)\n",
    "    sweep_cfg = multi_cfg[\"hydra\"][\"sweeper\"][\"params\"]\n",
    "\n",
    "    multirun_yaml_paths.append(multirun_yaml_path)\n",
    "    multi_cfgs.append(multirun_yaml_path)\n",
    "    sweep_cfgs.append(sweep_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'MLP_5x60', '++model.n_layers': 'choice(4,6,8)', '++model.n_nodes': 'choice(40,100,200)'},\n",
       " {'model': 'MLP_5x60', '++model.n_layers': 'choice(3,4)', '++model.n_nodes': 'choice(200,300)', 'optimizer': 'opt_v1', '++optimizer.batch': 'choice(8096, 16384, 32768)'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['model.n_layers', 'model.n_nodes'],\n",
       " ['model.n_layers', 'model.n_nodes', 'optimizer.batch']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use regex to find instances where prepend is ++\n",
    "# and store keys minus the ++ in a list\n",
    "import re\n",
    "\n",
    "sweep_keys_list = []\n",
    "\n",
    "for sweep_cfg, experiment_path in zip(sweep_cfgs, experiment_paths):\n",
    "    sweep_keys = []\n",
    "    for k, v in sweep_cfg.items():\n",
    "        if re.match(r\"\\+\\+\", k):\n",
    "            sweep_keys.append(k[2:])\n",
    "        elif re.match(r\"\\+\", k):\n",
    "            sweep_keys.append(k[2:])\n",
    "        elif re.match(r\"choice\", v):\n",
    "            if k == \"optimizer\":\n",
    "                sweep_keys.append(f\"{k}.loss_balancing.type\")\n",
    "            elif k == \"model\":\n",
    "                sweep_keys.append(k)\n",
    "        elif re.match(r\"glob\", v):\n",
    "            if k == \"optimizer\":\n",
    "              sweep_keys.append(k)\n",
    "            #   checkpoint_dir_paths = glob(f\"{experiment_path}*/.hydra/overrides.yaml\", recursive = True)\n",
    "            \n",
    "    sweep_keys_list.append(sweep_keys)\n",
    "\n",
    "sweep_keys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/0/checkpoints/962/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/1/checkpoints/726/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/2/checkpoints/1011/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/3/checkpoints/1152/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/4/checkpoints/602/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/5/checkpoints/21/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/6/checkpoints/1011/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/7/checkpoints/440/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/8/checkpoints/515/default'],\n",
       " ['/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/0/checkpoints/1310/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/1/checkpoints/1418/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/10/checkpoints/304/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/11/checkpoints/762/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/2/checkpoints/1724/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/3/checkpoints/1334/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/4/checkpoints/1668/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/5/checkpoints/1667/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/6/checkpoints/1011/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/7/checkpoints/964/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/8/checkpoints/1109/default',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/9/checkpoints/1249/default']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_paths_list = []\n",
    "for experiment_path in experiment_paths:\n",
    "    checkpoint_dir_paths = glob(f\"{experiment_path}/**/checkpoints*\", recursive = True)\n",
    "\n",
    "    best_model_paths = []\n",
    "    for checkpoint_dir_path in checkpoint_dir_paths:\n",
    "        subdirs = np.array(os.listdir(checkpoint_dir_path)).astype(int)\n",
    "        if len(subdirs) == 0:\n",
    "            best_model_path = checkpoint_dir_path+\"/empty/empty\"\n",
    "        else:\n",
    "            best_model_path = os.path.join(checkpoint_dir_path, f\"{subdirs.max()}/default\")\n",
    "        best_model_paths.append(best_model_path)\n",
    "\n",
    "    best_model_paths.sort()\n",
    "    best_model_paths_list.append(best_model_paths)\n",
    "best_model_paths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [['/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/0/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/1/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/2/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/3/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/4/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/5/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/6/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/7/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/8/.hydra/config.yaml'], ['/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/0/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/1/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/10/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/11/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/2/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/3/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/4/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/5/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/6/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/7/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/8/.hydra/config.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/9/.hydra/config.yaml']]\n",
      "2 [['/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/0/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/1/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/2/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/3/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/4/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/5/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/6/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/7/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/8/.hydra/overrides.yaml'], ['/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/0/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/1/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/10/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/11/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/2/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/3/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/4/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/5/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/6/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/7/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/8/.hydra/overrides.yaml', '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/9/.hydra/overrides.yaml']]\n"
     ]
    }
   ],
   "source": [
    "config_paths_list = []\n",
    "overrides_paths_list = []\n",
    "for best_model_paths in best_model_paths_list:\n",
    "    config_paths = [best_model_path.split(\"/\")[:-3]+[\".hydra/config.yaml\"] for best_model_path in best_model_paths]\n",
    "    config_paths = [\"/\".join(config_path) for config_path in config_paths]\n",
    "    config_paths_list.append(config_paths)\n",
    "    overrides_paths = [best_model_path.split(\"/\")[:-3]+[\".hydra/overrides.yaml\"] for best_model_path in best_model_paths]\n",
    "    overrides_paths = [\"/\".join(overrides_path) for overrides_path in overrides_paths]\n",
    "    overrides_paths_list.append(overrides_paths)\n",
    "print(len(config_paths_list), config_paths_list)\n",
    "print(len(overrides_paths_list), overrides_paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "\n",
    "sweep_values_df_list = []\n",
    "\n",
    "\n",
    "for config_paths, overrides_paths, sweep_keys in zip(config_paths_list, overrides_paths_list, sweep_keys_list):\n",
    "    sweep_values_df = pd.DataFrame(columns=sweep_keys)\n",
    "    for i, (config_path, overrides_path) in enumerate(zip(config_paths, overrides_paths)):\n",
    "        cfg = OmegaConf.load(config_path)\n",
    "        model_values = []\n",
    "        for k in sweep_keys:\n",
    "            if \".\" in k:\n",
    "                n_dots = k.count(\".\")\n",
    "                val = cfg[k.split(\".\")[0]]\n",
    "                for j in range(n_dots):\n",
    "                    val = val[k.split(\".\")[j+1]]\n",
    "                model_values.append(val)\n",
    "            else:\n",
    "                model_values.append(cfg[k])\n",
    "        sweep_values_df.loc[i] = model_values\n",
    "    \n",
    "\n",
    "    sweep_values_df_list.append(sweep_values_df)\n",
    "# print(len(sweep_values_df_list), sweep_values_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils.jax_flax import load_model\n",
    "\n",
    "\n",
    "loaded_models_list = []\n",
    "best_models_list = []\n",
    "best_params_list = []\n",
    "best_cfgs_list = []\n",
    "\n",
    "for best_model_paths in best_model_paths_list:\n",
    "    loaded_models = []\n",
    "    best_models = []\n",
    "    best_params = []\n",
    "    best_cfgs = []\n",
    "    for model_path in best_model_paths:\n",
    "        if \"empty\" in model_path:\n",
    "            loaded_model = None\n",
    "            best_model = None\n",
    "            best_param = None\n",
    "            best_cfg = None\n",
    "        else:\n",
    "            loaded_model = load_model(model_path)\n",
    "            best_model = loaded_model[0]\n",
    "            best_param = loaded_model[1]\n",
    "            best_cfg = loaded_model[2]\n",
    "\n",
    "        best_models.append(best_model)\n",
    "        best_params.append(best_param)\n",
    "        best_cfgs.append(best_cfg)\n",
    "        loaded_models.append(loaded_model)\n",
    "    loaded_models_list.append(loaded_models)\n",
    "    best_models_list.append(best_models)\n",
    "    best_params_list.append(best_params)\n",
    "    best_cfgs_list.append(best_cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nos_list = []\n",
    "\n",
    "# exp_categories = [\"A\", \"B\", \"C\"]\n",
    "exp_names_list = []\n",
    "\n",
    "for exp_main_path, best_model_paths in zip(experiment_paths, best_model_paths_list):\n",
    "    model_nos = []\n",
    "    exp_names = []\n",
    "    for best_model_path in best_model_paths:\n",
    "        model_no = best_model_path.split(\"/\")[-4]\n",
    "        # model_nos.append(f\"{exp_no}_{int(model_no)}\")\n",
    "        model_nos.append(model_no)\n",
    "        exp_names.append(exp_main_path.split(\"/\")[-1])\n",
    "    model_nos = np.array(model_nos).astype(int)\n",
    "    model_nos_list.append(model_nos)\n",
    "    exp_names_list.append(exp_names)\n",
    "# print(model_nos_list)\n",
    "# print(exp_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model.n_layers</th>\n",
       "      <th>model.n_nodes</th>\n",
       "      <th>optimizer.batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>8096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model.n_layers  model.n_nodes  optimizer.batch\n",
       "0                3            200             8096\n",
       "1                3            200            16384\n",
       "2                4            300            16384\n",
       "3                4            300            32768\n",
       "4                3            200            32768\n",
       "5                3            300             8096\n",
       "6                3            300            16384\n",
       "7                3            300            32768\n",
       "8                4            200             8096\n",
       "9                4            200            16384\n",
       "10               4            200            32768\n",
       "11               4            300             8096"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2024-03-26 20:01:45.624749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "9it [20:39, 137.70s/it]\n",
      "12it [35:05, 175.48s/it]\n"
     ]
    }
   ],
   "source": [
    "from utils.data import DataManager\n",
    "from utils.plotting import Plotter\n",
    "main_path = \"../\"\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "nc_path_old = \"\"\n",
    "\n",
    "model_comparison_df_list = []\n",
    "metric_dfs_list = []\n",
    "plot_classes_list = []\n",
    "\n",
    "\n",
    "for best_model_paths, best_cfgs, sweep_values_df, model_nos, exp_names in zip(best_model_paths_list, best_cfgs_list, sweep_values_df_list, model_nos_list, exp_names_list):\n",
    "    plot_classes = []\n",
    "    metrics_dfs = []\n",
    "    model_comparison_df = pd.DataFrame()\n",
    "    # for best_model, best_param, best_cfg in loaded_models:\n",
    "    i=0\n",
    "    for best_model_path, cfg in tqdm(zip(best_model_paths, best_cfgs)):\n",
    "        # evaluate\n",
    "        if \"empty\" in best_model_path:\n",
    "            plot_class = None\n",
    "            # metrics_df = pd.concat([sweep_values_df.loc[i], pd.Series({\"total\": [np.nan]})])\n",
    "            model_row = sweep_values_df.loc[i]\n",
    "    \n",
    "        else:\n",
    "            nc_path = os.path.abspath(os.path.join(main_path, cfg.data.data_path))\n",
    "            if nc_path != nc_path_old:\n",
    "                DM = DataManager(nc_path = nc_path, \n",
    "                            exclusion_radius = 1., \n",
    "                            input_coords = [\"z_cyl\", \"r\", \"CT\", \"TI_amb\"],\n",
    "                            output_vars = [\"U_z\", \"U_r\", \"P\"], \n",
    "                            val_split=0.1, \n",
    "                            development_mode=False)\n",
    "                nc_path_old = nc_path\n",
    "            plot_class = Plotter(DM, best_model_path)\n",
    "            sweep_vals = []\n",
    "            metrics_df, _ = plot_class.make_metric_df()\n",
    "            model_row = pd.concat([sweep_values_df.loc[i], metrics_df.loc['total']])\n",
    "        metrics_dfs.append(metrics_df)\n",
    "        plot_classes.append(plot_class)\n",
    "        model_comparison_df = pd.concat([model_comparison_df, model_row], axis=1)\n",
    "        i+=1\n",
    "    model_comparison_df = model_comparison_df.T.reset_index(drop=True)\n",
    "    tup_idx = [(model_no, exp_name) for  model_no, exp_name in zip(model_nos, exp_names)]\n",
    "    model_comparison_df.index = pd.Index(tup_idx)\n",
    "    # model_comparison_df.index = model_nos\n",
    "    model_comparison_df[\"paths\"] = best_model_paths\n",
    "    \n",
    "    model_comparison_df_list.append(model_comparison_df)\n",
    "    metric_dfs_list.append(metrics_dfs)\n",
    "    plot_classes_list.append(plot_classes)\n",
    "# model_comparison_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/0/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/1/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/2/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/3/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/4/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/5/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/6/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/7/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/8/final_model'],\n",
       " ['/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/0/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/1/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/10/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/11/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/2/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/3/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/4/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/5/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/6/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/7/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/8/final_model',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/9/final_model']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_model_paths = [best_model_path.split(\"/\")[:-3]+[\"final_model\"] for best_model_path in best_model_paths]\n",
    "\n",
    "final_model_paths_list = []\n",
    "\n",
    "for best_model_paths in best_model_paths_list:\n",
    "    final_model_paths = []\n",
    "    for best_model_path in best_model_paths:\n",
    "        if \"empty\" in best_model_path:\n",
    "            final_model_path = best_model_path.split(\"/\")[:-3]+[\"empty\"]\n",
    "            final_model_paths.append(final_model_path)\n",
    "        else:\n",
    "            final_model_path = best_model_path.split(\"/\")[:-3]+[\"final_model\"]\n",
    "            final_model_paths.append(final_model_path)\n",
    "\n",
    "    final_model_paths = [\"/\".join(final_model_path) for final_model_path in final_model_paths]\n",
    "\n",
    "    final_model_paths_list.append(final_model_paths)\n",
    "final_model_paths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_bools_list = []\n",
    "for final_model_paths, model_comparison_df in zip(final_model_paths_list, model_comparison_df_list):\n",
    "    finished_bools = []\n",
    "    for final_model_path in final_model_paths:\n",
    "        finished_bools.append(os.path.exists(final_model_path))\n",
    "\n",
    "    model_comparison_df[\"finished\"] = finished_bools\n",
    "    finished_bools_list.append(finished_bools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/0/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/1/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/2/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/3/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/4/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/5/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/6/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/7/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment1/8/tensorboard'],\n",
       " ['/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/0/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/1/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/10/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/11/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/2/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/3/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/4/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/5/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/6/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/7/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/8/tensorboard',\n",
       "  '/home/jpsch/code/jax-flax-wake-pinn/Results/Pre-experiment2/01-16-34/9/tensorboard']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tb_paths = [final_model_path.split(\"/\")[:-1]+[\"tensorboard\"] for final_model_path in final_model_paths]\n",
    "\n",
    "tb_paths_list = []\n",
    "\n",
    "for final_model_paths in final_model_paths_list:\n",
    "    tb_paths = []\n",
    "    for final_model_path in final_model_paths:\n",
    "        if \"empty\" in final_model_path:\n",
    "            tb_path = final_model_path.split(\"/\")[:-1]+[\"empty\"]\n",
    "            tb_paths.append(tb_path)\n",
    "        else:\n",
    "            tb_path = final_model_path.split(\"/\")[:-1]+[\"tensorboard\"]\n",
    "            tb_paths.append(tb_path)\n",
    "\n",
    "    tb_paths = [\"/\".join(tb_path) for tb_path in tb_paths]\n",
    "    tb_paths_list.append(tb_paths)\n",
    "tb_paths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe of timing s with tensorboard logs\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils.data import TensorBoardLoader\n",
    "\n",
    "tb_dfs_list = []\n",
    "for i, (tb_paths, model_comparison_df, model_nos) in enumerate(zip(tb_paths_list, model_comparison_df_list, model_nos_list)):\n",
    "\n",
    "    tb_dfs = []\n",
    "    timings = pd.DataFrame(columns=[\"total_time[h]\", \"epochs\", \"time_per_epoch[m]\"])\n",
    "    for j, tb_path in enumerate(tb_paths):\n",
    "        if \"empty\" in tb_path:\n",
    "            timings.loc[j] = [np.nan, np.nan, np.nan]\n",
    "            df = None\n",
    "        else:\n",
    "            tb_class = TensorBoardLoader(tb_path)\n",
    "            time_data, epochs_data, loss_data = tb_class.load_scalar_events(\"Loss/data\")\n",
    "            total_epochs = epochs_data[-1]\n",
    "            total_time = (time_data[-1]-time_data[0])/60/60 # total time in hours\n",
    "            time_per_epoch = (total_time*60)/total_epochs # time per epoch in minutes\n",
    "            timings.loc[j] = [total_time, total_epochs, time_per_epoch]\n",
    "            df = tb_class.load_df()\n",
    "        tb_dfs.append(df)\n",
    "\n",
    "    timings.index = model_comparison_df_list[i].index\n",
    "    model_comparison_df_list[i] = model_comparison_df_list[i].join(timings)\n",
    "    # model_comparison_df_list[i] = pd.concat([model_comparison_df, timings])\n",
    "    tb_dfs_list.append(tb_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model.n_layers</th>\n",
       "      <th>model.n_nodes</th>\n",
       "      <th>optimizer.batch</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE_pinn</th>\n",
       "      <th>paths</th>\n",
       "      <th>finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>8096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>30.333341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287227</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>22.168833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.892798</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>97.794485</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>6678758.5</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>32.347095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.815332</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>23.007352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.547626</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>8096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>18.100477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>327.1651</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>47.706488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.739264</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>19.304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>155.843597</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>8096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>28.876644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00683</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>55.12012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>20.889378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032008</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>Pre-experiment2</th>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>8096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>182.964033</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>60257484.0</td>\n",
       "      <td>/home/jpsch/code/jax-flax-wake-pinn/Results/Pr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model.n_layers model.n_nodes optimizer.batch  MSE  \\\n",
       "0  Pre-experiment2              3           200            8096  0.0   \n",
       "1  Pre-experiment2              3           200           16384  0.0   \n",
       "10 Pre-experiment2              4           300           16384  0.0   \n",
       "11 Pre-experiment2              4           300           32768  0.0   \n",
       "2  Pre-experiment2              3           200           32768  0.0   \n",
       "3  Pre-experiment2              3           300            8096  0.0   \n",
       "4  Pre-experiment2              3           300           16384  0.0   \n",
       "5  Pre-experiment2              3           300           32768  0.0   \n",
       "6  Pre-experiment2              4           200            8096  0.0   \n",
       "7  Pre-experiment2              4           200           16384  0.0   \n",
       "8  Pre-experiment2              4           200           32768  0.0   \n",
       "9  Pre-experiment2              4           300            8096  0.0   \n",
       "\n",
       "                         MAE      RMSE        MAPE        R2    MSE_pinn  \\\n",
       "0  Pre-experiment2  0.000074  0.000145   30.333341       1.0    0.287227   \n",
       "1  Pre-experiment2  0.000081  0.000156   22.168833       1.0    7.892798   \n",
       "10 Pre-experiment2  0.000184  0.000579   97.794485  0.999998   6678758.5   \n",
       "11 Pre-experiment2  0.000104  0.000255   32.347095       1.0   27.815332   \n",
       "2  Pre-experiment2  0.000087  0.000179   23.007352       1.0    0.547626   \n",
       "3  Pre-experiment2  0.000076  0.000195   18.100477       1.0    327.1651   \n",
       "4  Pre-experiment2  0.000087  0.000173   47.706488       1.0    5.739264   \n",
       "5  Pre-experiment2  0.000076  0.000193      19.304       1.0  155.843597   \n",
       "6  Pre-experiment2  0.000079  0.000159   28.876644       1.0     0.00683   \n",
       "7  Pre-experiment2  0.000082  0.000153    55.12012       1.0    0.002147   \n",
       "8  Pre-experiment2  0.000092  0.000178   20.889378       1.0    0.032008   \n",
       "9  Pre-experiment2  0.000203  0.000456  182.964033  0.999999  60257484.0   \n",
       "\n",
       "                                                                paths  \\\n",
       "0  Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "1  Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "10 Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "11 Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "2  Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "3  Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "4  Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "5  Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "6  Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "7  Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "8  Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "9  Pre-experiment2  /home/jpsch/code/jax-flax-wake-pinn/Results/Pr...   \n",
       "\n",
       "                    finished  \n",
       "0  Pre-experiment2      True  \n",
       "1  Pre-experiment2      True  \n",
       "10 Pre-experiment2      True  \n",
       "11 Pre-experiment2      True  \n",
       "2  Pre-experiment2      True  \n",
       "3  Pre-experiment2      True  \n",
       "4  Pre-experiment2      True  \n",
       "5  Pre-experiment2     False  \n",
       "6  Pre-experiment2      True  \n",
       "7  Pre-experiment2      True  \n",
       "8  Pre-experiment2      True  \n",
       "9  Pre-experiment2     False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df = pd.concat(model_comparison_df_list)\n",
    "hl_df = model_comparison_df.reset_index()\n",
    "\n",
    "# Dropping cases where the batch size is not 8096\n",
    "# Replace nan with 0.0 for colloc_data_rati\n",
    "# hl_df = hl_df[hl_df[\"optimizer.batch\"]==np.nan]\n",
    "\n",
    "pre_exp1_mask = hl_df[\"level_1\"]==\"Pre-experiment1\"\n",
    "pre_exp2_mask = hl_df[\"level_1\"]==\"Pre-experiment2\"\n",
    "\n",
    "hl_df.loc[pre_exp1_mask, \"optimizer.batch\"] = 8096\n",
    "hl_df = hl_df.where(hl_df[\"optimizer.batch\"]==8096, inplace=False).dropna(axis=0)\n",
    "hl_df = hl_df[hl_df[\"level_1\"]==\"Pre-experiment1\"]\n",
    "hl_df.drop(columns=[\"level_0\", \"level_1\", \"paths\", \"optimizer.batch\", \"time_per_epoch[m]\", \"finished\", \"R2\"], inplace=True)\n",
    "\n",
    "for column in hl_df.columns:\n",
    "    if column == \"epochs\":\n",
    "       hl_df[column] = hl_df[column].astype(int)\n",
    "    elif column == \"total_time[h]\":\n",
    "        hl_df[column] = hl_df[column].astype(float).round(3).astype(str)\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "        # hl_df[column] = hl_df[column].astype(float).round(5).astype(str)\n",
    "\n",
    "hl_df.columns = [r'$n_\\textrm{layers}$', r'$m_\\textrm{neurons}$', r\"$\\textrm{MSE}$\", r\"$\\textrm{MAE}$\", r\"$\\textrm{RMSE}$\", r\"$\\textrm{MAPE}$\", r\"$\\textrm{MSE}_\\phi$\",\n",
    "       'Wall time [h]', 'epochs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom formatter for scientific notation\n",
    "scientific_formatter = \"{:.2e}\".format\n",
    "hl_df.to_latex(\"../figures/Pre-experiment1.tex\", \n",
    "                float_format=\"{:.2e}\".format,\n",
    "                escape=False)\n",
    "\n",
    "hl_df.to_latex(\"../figures/Pre-experiment1_f_formatted.tex\", \n",
    "                float_format=\"{:.2f}\".format,\n",
    "                escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load latex table\n",
    "with open(\"../figures/Pre-experiment1.tex\", 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(\"../figures/Pre-experiment1_f_formatted.tex\", 'r') as f:\n",
    "    lines2 = f.readlines()\n",
    "\n",
    "# Change inital lines and line indicatiors to match Journal of Physics and own style\n",
    "\n",
    "for i, _ in enumerate(lines):\n",
    "    splitted_line = lines[i].split(\"&\")\n",
    "    for j, splited in enumerate(splitted_line):\n",
    "        if (r\"e-\" in splited or r\"e+\" in splited):\n",
    "            power = int(splited.split(r\"e\")[1])\n",
    "            if np.abs(power) < 3:\n",
    "                splitted2 = lines2[i].split(\"&\")\n",
    "                splitted_line[j] = splitted2[j]\n",
    "            else:\n",
    "                splitted_line[j] = r\"\\num{\"+splited+r\"}\"\n",
    "\n",
    "    if r\"\\\\\" in lines[i]:\n",
    "        lines[i] = lines[i].replace(r\"\\\\\", r\"\\cr\")\n",
    "    if \"&\" in lines[i]:\n",
    "        lines[i] = \"&\".join(splitted_line[1:])\n",
    "\n",
    "start_lines = [r\"\\begin{tabular}{cccccccccc}\"+\"\\n\", r\"\\br\"+\"\\n\"]\n",
    "lines[:2] = start_lines\n",
    "lines[3] = r\"\\mr\"+\"\\n\"\n",
    "lines[-2] = r\"\\br\"+\"\\n\"\n",
    "lines[-1] = r\"\\end{tabular}\"+\"\\n\"\n",
    "\n",
    "# write as latex file\n",
    "with open(\"../figures/Pre-experiment1.tex\", 'w') as f:\n",
    "    f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_57e7b_row0_col2, #T_57e7b_row0_col4, #T_57e7b_row1_col6, #T_57e7b_row2_col3, #T_57e7b_row2_col5 {\n",
       "  background-color: darkgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_57e7b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_57e7b_level0_col0\" class=\"col_heading level0 col0\" >$n_\\textrm{layers}$</th>\n",
       "      <th id=\"T_57e7b_level0_col1\" class=\"col_heading level0 col1\" >$m_\\textrm{neurons}$</th>\n",
       "      <th id=\"T_57e7b_level0_col2\" class=\"col_heading level0 col2\" >$\\textrm{MSE}$</th>\n",
       "      <th id=\"T_57e7b_level0_col3\" class=\"col_heading level0 col3\" >$\\textrm{MAE}$</th>\n",
       "      <th id=\"T_57e7b_level0_col4\" class=\"col_heading level0 col4\" >$\\textrm{RMSE}$</th>\n",
       "      <th id=\"T_57e7b_level0_col5\" class=\"col_heading level0 col5\" >$\\textrm{MAPE}$</th>\n",
       "      <th id=\"T_57e7b_level0_col6\" class=\"col_heading level0 col6\" >$\\textrm{MSE}_\\phi$</th>\n",
       "      <th id=\"T_57e7b_level0_col7\" class=\"col_heading level0 col7\" >Wall time [h]</th>\n",
       "      <th id=\"T_57e7b_level0_col8\" class=\"col_heading level0 col8\" >epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_57e7b_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_57e7b_row0_col0\" class=\"data row0 col0\" >4</td>\n",
       "      <td id=\"T_57e7b_row0_col1\" class=\"data row0 col1\" >100</td>\n",
       "      <td id=\"T_57e7b_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_57e7b_row0_col3\" class=\"data row0 col3\" >0.000071</td>\n",
       "      <td id=\"T_57e7b_row0_col4\" class=\"data row0 col4\" >0.000159</td>\n",
       "      <td id=\"T_57e7b_row0_col5\" class=\"data row0 col5\" >15.321644</td>\n",
       "      <td id=\"T_57e7b_row0_col6\" class=\"data row0 col6\" >0.042449</td>\n",
       "      <td id=\"T_57e7b_row0_col7\" class=\"data row0 col7\" >14.196</td>\n",
       "      <td id=\"T_57e7b_row0_col8\" class=\"data row0 col8\" >897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57e7b_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_57e7b_row1_col0\" class=\"data row1 col0\" >4</td>\n",
       "      <td id=\"T_57e7b_row1_col1\" class=\"data row1 col1\" >200</td>\n",
       "      <td id=\"T_57e7b_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_57e7b_row1_col3\" class=\"data row1 col3\" >0.000079</td>\n",
       "      <td id=\"T_57e7b_row1_col4\" class=\"data row1 col4\" >0.000159</td>\n",
       "      <td id=\"T_57e7b_row1_col5\" class=\"data row1 col5\" >28.876644</td>\n",
       "      <td id=\"T_57e7b_row1_col6\" class=\"data row1 col6\" >0.006830</td>\n",
       "      <td id=\"T_57e7b_row1_col7\" class=\"data row1 col7\" >27.603</td>\n",
       "      <td id=\"T_57e7b_row1_col8\" class=\"data row1 col8\" >1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57e7b_level0_row2\" class=\"row_heading level0 row2\" >6</th>\n",
       "      <td id=\"T_57e7b_row2_col0\" class=\"data row2 col0\" >8</td>\n",
       "      <td id=\"T_57e7b_row2_col1\" class=\"data row2 col1\" >40</td>\n",
       "      <td id=\"T_57e7b_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
       "      <td id=\"T_57e7b_row2_col3\" class=\"data row2 col3\" >0.000065</td>\n",
       "      <td id=\"T_57e7b_row2_col4\" class=\"data row2 col4\" >0.000170</td>\n",
       "      <td id=\"T_57e7b_row2_col5\" class=\"data row2 col5\" >9.196713</td>\n",
       "      <td id=\"T_57e7b_row2_col6\" class=\"data row2 col6\" >0.293689</td>\n",
       "      <td id=\"T_57e7b_row2_col7\" class=\"data row2 col7\" >16.863</td>\n",
       "      <td id=\"T_57e7b_row2_col8\" class=\"data row2 col8\" >1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57e7b_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_57e7b_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_57e7b_row3_col1\" class=\"data row3 col1\" >40</td>\n",
       "      <td id=\"T_57e7b_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
       "      <td id=\"T_57e7b_row3_col3\" class=\"data row3 col3\" >0.000093</td>\n",
       "      <td id=\"T_57e7b_row3_col4\" class=\"data row3 col4\" >0.000193</td>\n",
       "      <td id=\"T_57e7b_row3_col5\" class=\"data row3 col5\" >40.012421</td>\n",
       "      <td id=\"T_57e7b_row3_col6\" class=\"data row3 col6\" >24.793255</td>\n",
       "      <td id=\"T_57e7b_row3_col7\" class=\"data row3 col7\" >13.162</td>\n",
       "      <td id=\"T_57e7b_row3_col8\" class=\"data row3 col8\" >1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57e7b_level0_row4\" class=\"row_heading level0 row4\" >3</th>\n",
       "      <td id=\"T_57e7b_row4_col0\" class=\"data row4 col0\" >6</td>\n",
       "      <td id=\"T_57e7b_row4_col1\" class=\"data row4 col1\" >40</td>\n",
       "      <td id=\"T_57e7b_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
       "      <td id=\"T_57e7b_row4_col3\" class=\"data row4 col3\" >0.000144</td>\n",
       "      <td id=\"T_57e7b_row4_col4\" class=\"data row4 col4\" >0.000283</td>\n",
       "      <td id=\"T_57e7b_row4_col5\" class=\"data row4 col5\" >82.688969</td>\n",
       "      <td id=\"T_57e7b_row4_col6\" class=\"data row4 col6\" >0.034803</td>\n",
       "      <td id=\"T_57e7b_row4_col7\" class=\"data row4 col7\" >14.571</td>\n",
       "      <td id=\"T_57e7b_row4_col8\" class=\"data row4 col8\" >1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57e7b_level0_row5\" class=\"row_heading level0 row5\" >4</th>\n",
       "      <td id=\"T_57e7b_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_57e7b_row5_col1\" class=\"data row5 col1\" >100</td>\n",
       "      <td id=\"T_57e7b_row5_col2\" class=\"data row5 col2\" >0.000000</td>\n",
       "      <td id=\"T_57e7b_row5_col3\" class=\"data row5 col3\" >0.000157</td>\n",
       "      <td id=\"T_57e7b_row5_col4\" class=\"data row5 col4\" >0.000467</td>\n",
       "      <td id=\"T_57e7b_row5_col5\" class=\"data row5 col5\" >149.544946</td>\n",
       "      <td id=\"T_57e7b_row5_col6\" class=\"data row5 col6\" >3.212239</td>\n",
       "      <td id=\"T_57e7b_row5_col7\" class=\"data row5 col7\" >16.843</td>\n",
       "      <td id=\"T_57e7b_row5_col8\" class=\"data row5 col8\" >853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57e7b_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_57e7b_row6_col0\" class=\"data row6 col0\" >8</td>\n",
       "      <td id=\"T_57e7b_row6_col1\" class=\"data row6 col1\" >100</td>\n",
       "      <td id=\"T_57e7b_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
       "      <td id=\"T_57e7b_row6_col3\" class=\"data row6 col3\" >0.000249</td>\n",
       "      <td id=\"T_57e7b_row6_col4\" class=\"data row6 col4\" >0.000626</td>\n",
       "      <td id=\"T_57e7b_row6_col5\" class=\"data row6 col5\" >303.905756</td>\n",
       "      <td id=\"T_57e7b_row6_col6\" class=\"data row6 col6\" >23321764.000000</td>\n",
       "      <td id=\"T_57e7b_row6_col7\" class=\"data row6 col7\" >16.54</td>\n",
       "      <td id=\"T_57e7b_row6_col8\" class=\"data row6 col8\" >691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57e7b_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_57e7b_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_57e7b_row7_col1\" class=\"data row7 col1\" >200</td>\n",
       "      <td id=\"T_57e7b_row7_col2\" class=\"data row7 col2\" >0.000001</td>\n",
       "      <td id=\"T_57e7b_row7_col3\" class=\"data row7 col3\" >0.000549</td>\n",
       "      <td id=\"T_57e7b_row7_col4\" class=\"data row7 col4\" >0.001083</td>\n",
       "      <td id=\"T_57e7b_row7_col5\" class=\"data row7 col5\" >360.843594</td>\n",
       "      <td id=\"T_57e7b_row7_col6\" class=\"data row7 col6\" >47267.316406</td>\n",
       "      <td id=\"T_57e7b_row7_col7\" class=\"data row7 col7\" >28.675</td>\n",
       "      <td id=\"T_57e7b_row7_col8\" class=\"data row7 col8\" >766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57e7b_level0_row8\" class=\"row_heading level0 row8\" >5</th>\n",
       "      <td id=\"T_57e7b_row8_col0\" class=\"data row8 col0\" >6</td>\n",
       "      <td id=\"T_57e7b_row8_col1\" class=\"data row8 col1\" >200</td>\n",
       "      <td id=\"T_57e7b_row8_col2\" class=\"data row8 col2\" >0.000002</td>\n",
       "      <td id=\"T_57e7b_row8_col3\" class=\"data row8 col3\" >0.000403</td>\n",
       "      <td id=\"T_57e7b_row8_col4\" class=\"data row8 col4\" >0.001294</td>\n",
       "      <td id=\"T_57e7b_row8_col5\" class=\"data row8 col5\" >114.580328</td>\n",
       "      <td id=\"T_57e7b_row8_col6\" class=\"data row8 col6\" >0.141783</td>\n",
       "      <td id=\"T_57e7b_row8_col7\" class=\"data row8 col7\" >7.807</td>\n",
       "      <td id=\"T_57e7b_row8_col8\" class=\"data row8 col8\" >272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7d115e27a830>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_df = hl_df.sort_values(by=r\"$\\textrm{MSE}$\", ascending=True)\n",
    "hl_df = hl_df.style.highlight_min(subset=[r\"$\\textrm{MSE}$\", r\"$\\textrm{MAE}$\", r\"$\\textrm{RMSE}$\", r\"$\\textrm{MAPE}$\", r\"$\\textrm{MSE}_\\phi$\"], color = 'darkgrey')\n",
    "# hl_df = hl_df.highlight_max(subset=[r\"$\\textrm{R}^2$\"], color = 'darkgrey', axis = 0)\n",
    "\n",
    "hl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highlighted_df.to_latex(\"model_comparison.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# for i, (plot_classes_list, tb_dfs_list, plot_classes_list) in enumerate(zip(plot_classes_list, tb_dfs_list, plot_classes_list)):\n",
    "#     for j, (df, plot_class) in enumerate(zip(tb_dfs, plot_classes)):\n",
    "#         if plot_class is None:\n",
    "#             continue\n",
    "#         title = final_model_paths[j].split(\"/\")[-2]\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "#         plt.title(f\"Exp: {i}, Model {title}\")\n",
    "#         if \"Loss/pinn\" in df.columns:\n",
    "#             df.plot(\"step\",[\"Loss/tot\", \"loss\", \"Loss/pinn\", \"Loss/val\"], logy=True, ax=axes[0])\n",
    "#             df.plot(\"step\",[\"Loss/alpha_data\", \"Loss/alpha_pinn\"], logy=False, ax=axes[1])\n",
    "#         else:\n",
    "#             df.plot(\"step\",[\"loss\", \"Loss/val\"], logy=True, ax=axes[0])\n",
    "\n",
    "#         plot_class.plot_pred_triplet(\"U_z\", flowcase=0)\n",
    "#         plot_class.plot_pred_triplet(\"U_r\", flowcase=0)\n",
    "#         plot_class.plot_pred_triplet(\"P\", flowcase=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
